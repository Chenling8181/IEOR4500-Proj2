{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:red'>Project 2.  Due October 23</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\00\\AppData\\Local\\Temp\\ipykernel_32796\\1189900070.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width: 90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this project we develop a first-order algorithm to construct a portfolio using intraday data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will have data involving $n$ assets, and use the first $T$ days of the data to compute the portfolio.\n",
    "##### The computation will produce a weight $x_i$ for each asset $i = 1,...,n$, which could be long or short.\n",
    "##### We assume that on each day, a position is taken at the open, and closed at noon.  So we define:\n",
    "$$ p^o_{j,t} = \\ \\text{price of asset $j$ on day $t$ at the open}$$\n",
    "$$ p^1_{j,t} = \\ \\text{price of asset $j$ on day $t$ at noon}$$\n",
    "$$ r_{j,t} =  \\ \\frac{p^1_{j,t} - p^o_{j,t}}{p^o_{j,t}} = \\ \\text{return earned by asset $j$ on day $t$.}$$\n",
    "$$ \\bar r_j = \\ \\frac{1}{T} \\sum_{t = 1}^T r_{j,t} = \\ \\text{average return earned by asset $j$.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimization problem to solve depends on two parameters: $\\theta \\ge 0$ and $\\pi > 0 0$.\n",
    "####\n",
    "$$ \\text{minimize} \\ \\left(-\\sum_{j = 1}^n \\bar r_j x_j\\right) \\ + \\ \\theta \\left( \\frac{1}{T} \\sum_{t = 1}^{T}\\left[\\sum_{j = 1}^n (r_{j,t} -  \\bar r_j)x_j\\right]^\\pi\\right)^{1/\\pi}$$\n",
    "#### \n",
    "#### There are no constraints on the quantities $x_j$.\n",
    "#### The first sum is minus the average return earned by the portfolio.  In the second sum, the quantity inside the square brackets is the excess return earned by the portfolio on day $t$, magnified by the power $\\pi$.  The quantity $\\theta$ is a risk aversion parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:red'> Task 1. Develop a first-order method to address this computational problem.</span>\n",
    "#### \n",
    "#### Your method should work with values of $T$ at least $100$. Use the data we provide for AMZN, NFLX, TSLA, i.e., $n = 3$. \n",
    "###\n",
    "#### Make sure your code works with $\\pi = 0.5, 2, 4, 6$, and $\\theta = 0.1, 10, 1000, 10^5, 10^6$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# construct interval data\n",
    "from datetime import datetime, time\n",
    "from datetime import date\n",
    "import warnings\n",
    "\n",
    "# Suppress the warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_TSLA = pd.read_csv('TSLA.csv', skiprows = 3)\n",
    "df_TSLA = df_TSLA.loc[:, ['Dates', 'Close']].dropna()\n",
    "df_TSLA['Dates'] = pd.to_datetime(df_TSLA['Dates'])\n",
    "start = datetime.strptime('09:30:00', '%H:%M:%S').time()\n",
    "noon = datetime.strptime('12:00:00', '%H:%M:%S').time()\n",
    "df_TSLA['Date']=df_TSLA['Dates'].dt.date\n",
    "df_TSLA = df_TSLA[(df_TSLA['Dates'].dt.time==noon) | (df_TSLA['Dates'].dt.time==start)]\n",
    "\n",
    "\n",
    "\n",
    "df_AMZN = pd.read_csv('AMZN.csv', skiprows = 3)\n",
    "#missing value backfill\n",
    "df_AMZN['Dates'][0]='1/4/21 9:30'\n",
    "df_AMZN = df_AMZN.loc[:, ['Dates', 'Close']].dropna()\n",
    "df_AMZN['Dates'] = pd.to_datetime(df_AMZN['Dates'])\n",
    "start = datetime.strptime('09:30:00', '%H:%M:%S').time()\n",
    "noon = datetime.strptime('12:00:00', '%H:%M:%S').time()\n",
    "noon_correction = datetime.strptime('12:01:00', '%H:%M:%S').time()\n",
    "df_AMZN['Date']=df_AMZN['Dates'].dt.date\n",
    "df_AMZN = df_AMZN[(df_AMZN['Dates'].dt.time==noon) | \\\n",
    "                  (df_AMZN['Dates'].dt.time==start) | \\\n",
    "                    ((df_AMZN['Dates'].dt.time==noon_correction) & (df_AMZN['Date'] == date(2021, 4, 20)) )\\\n",
    "                        |((df_AMZN['Dates'].dt.time==noon_correction) & (df_AMZN['Date'] == date(2021, 6, 14)) )]\n",
    "\n",
    "df_NFLX = pd.read_csv('NFLX.csv', skiprows = 3)\n",
    "#missing value backfill\n",
    "df_NFLX['Dates'][0]='2/1/21 9:30'\n",
    "df_NFLX = df_NFLX.loc[:, ['Dates', 'Close']].dropna()\n",
    "df_NFLX['Dates'] = pd.to_datetime(df_NFLX['Dates'])\n",
    "start = datetime.strptime('09:30:00', '%H:%M:%S').time()\n",
    "noon = datetime.strptime('12:00:00', '%H:%M:%S').time()\n",
    "df_NFLX['Date']=df_NFLX['Dates'].dt.date\n",
    "df_NFLX = df_NFLX[(df_NFLX['Dates'].dt.time==noon) | (df_NFLX['Dates'].dt.time==start)]\n",
    "\n",
    "\n",
    "mask1 = df_TSLA['Date'].isin(df_AMZN['Date'])\n",
    "mask2 = df_TSLA['Date'].isin(df_NFLX['Date'])\n",
    "intersection_dates = df_TSLA['Date'][mask1&mask2]\n",
    "\n",
    "AMZN = np.array(df_AMZN[df_AMZN['Date'].isin(intersection_dates)].groupby('Date')['Close'].pct_change().dropna())[:100]\n",
    "NFLX = np.array(df_NFLX[df_NFLX['Date'].isin(intersection_dates)].groupby('Date')['Close'].pct_change().dropna())[:100]\n",
    "TSLA = np.array(df_TSLA[df_TSLA['Date'].isin(intersection_dates)].groupby('Date')['Close'].pct_change().dropna())[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data, parameters, and objective function here\n",
    "#r_jt = np.random.rand(T, n)  # Use random returns to test your function so that you don't have to read data\n",
    "r_jt = np.vstack((AMZN,NFLX,TSLA)).T\n",
    "bar_r_j = np.mean(r_jt, axis=0)  # Average returns for each asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions to Compute Objective Function and Approximate the Gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_objective(x_j, r_jt, bar_r_j, pi, theta):\n",
    "    return -np.sum(bar_r_j * x_j) + theta * (np.mean((abs(np.dot(r_jt - bar_r_j, x_j)) ** pi)) ** (1/pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_gradient(x_j, r_jt, bar_r_j, pi, theta):\n",
    "\n",
    "    change = [1e-5,0,0]\n",
    "    grad1=(compute_objective(x_j+change, r_jt, bar_r_j, pi, theta) \\\n",
    "        - compute_objective(x_j-change, r_jt, bar_r_j, pi, theta))/(2*change[0])\n",
    "    \n",
    "\n",
    "    change = [0,1e-5,0]    \n",
    "    grad2=(compute_objective(x_j+change, r_jt, bar_r_j, pi, theta) \\\n",
    "        - compute_objective(x_j-change, r_jt, bar_r_j, pi, theta))/(2*change[1])\n",
    "\n",
    "\n",
    "    change = [0,0,1e-5]\n",
    "    grad3=(compute_objective(x_j+change, r_jt, bar_r_j, pi, theta) \\\n",
    "        - compute_objective(x_j-change, r_jt, bar_r_j, pi, theta))/(2*change[2])\n",
    "\n",
    "    return np.array([grad1,grad2,grad3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(10)\n",
    "# # Initial random portfolio weights.\n",
    "# n=3\n",
    "# T=100\n",
    "# x_j = np.random.rand(n) \n",
    "# r_jt = np.random.rand(T, n)\n",
    "# bar_r_j = np.mean(r_jt, axis=0)  \n",
    "# pi=0.5\n",
    "# theta=0.1\n",
    "# compute_objective(x_j, r_jt, bar_r_j, pi, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Order Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def first_order(x_j, r_jt, bar_r_j, pi, theta):\n",
    "    print(' ')\n",
    "    print('theta:', theta,' ', 'pi:', pi)\n",
    "    # Gradient Descent terminal conditions\n",
    "    max_iterations = 1000\n",
    "    tolerance = 1e-4\n",
    "\n",
    "    # Gradient Descent Hyperparameters: Backtracking Line Search with Momentum\n",
    "    alpha = 0.3  # Backtracking parameter (you can adjust this)\n",
    "    beta = 0.90  # Backtracking parameter (you can adjust this)\n",
    "    old_delta = 0 \n",
    "    mu=0.1 # Monemtum parameter (you can adjust this)\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "\n",
    "        gradient = approximate_gradient(x_j, r_jt, bar_r_j, pi, theta)\n",
    "        \n",
    "        # Backtracking Line Search\n",
    "        t = 1.0\n",
    "        while compute_objective(x_j - t * gradient, r_jt, bar_r_j, pi, theta) > \\\n",
    "            compute_objective(x_j, r_jt, bar_r_j, pi, theta) - alpha * t * np.linalg.norm(gradient) ** 2:\n",
    "            t *= beta\n",
    "            if t < 1e-3 and compute_objective(x_j - t * gradient, r_jt, bar_r_j, pi, theta)<\\\n",
    "                compute_objective(x_j, r_jt, bar_r_j, pi, theta):\n",
    "                break\n",
    "\n",
    "        # Update portfolio weights with momentum\n",
    "        gradstep = -t * gradient\n",
    "        delta = gradstep + (1 - mu)*old_delta\n",
    "        x_j += delta\n",
    "        old_delta = old_delta\n",
    "\n",
    "        # Check for convergence\n",
    "        if abs(np.linalg.norm(gradient)) < tolerance:\n",
    "            print('Converged with in', iteration+1, 'iterations')    \n",
    "            break\n",
    "\n",
    "    if abs(np.linalg.norm(gradient)) > tolerance: \n",
    "        print('Max iteration reached')\n",
    "        \n",
    "    print('Gradient norm:', np.linalg.norm(gradient))\n",
    "    print('Objective value: ', compute_objective(x_j, r_jt, bar_r_j, pi, theta))\n",
    "    print('Final_portfolio_weights ', x_j)     \n",
    "\n",
    "    # Final portfolio allocation\n",
    "    return x_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "theta: 0.1   pi: 0.5\n",
      "Max iteration reached\n",
      "Gradient norm: 0.002320547429989169\n",
      "Objective value:  6.754235046413793e-06\n",
      "Final_portfolio_weights  [ 0.60393063 -0.13605496 -0.15981191]\n",
      " \n",
      "theta: 0.1   pi: 2.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.00011676914032580526\n",
      "Objective value:  2.7662727841066084e-05\n",
      "Final_portfolio_weights  [ 0.41653588 -0.07294781 -0.32042219]\n",
      " \n",
      "theta: 0.1   pi: 4.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0004029904106313674\n",
      "Objective value:  9.671399108399605e-05\n",
      "Final_portfolio_weights  [ 0.21279053 -0.00420672 -0.1123706 ]\n",
      " \n",
      "theta: 0.1   pi: 6.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0005835701876840125\n",
      "Objective value:  4.5180554986642395e-05\n",
      "Final_portfolio_weights  [ 0.06949977  0.00307511 -0.03397779]\n",
      " \n",
      "theta: 10.0   pi: 0.5\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0006278658224675351\n",
      "Objective value:  2.4857889898773006e-08\n",
      "Final_portfolio_weights  [ 4.10509670e-07 -6.94061338e-08 -1.75966317e-07]\n",
      " \n",
      "theta: 10.0   pi: 2.0\n",
      "Converged with in 125 iterations\n",
      "Gradient norm: 7.933585160634839e-05\n",
      "Objective value:  2.248138305501266e-08\n",
      "Final_portfolio_weights  [ 1.22722295e-07  2.24179483e-08 -1.16971199e-07]\n",
      " \n",
      "theta: 10.0   pi: 4.0\n",
      "Converged with in 142 iterations\n",
      "Gradient norm: 3.057432019438018e-05\n",
      "Objective value:  2.3960664163845134e-08\n",
      "Final_portfolio_weights  [ 1.98316376e-07  2.49485188e-08 -1.68609887e-08]\n",
      " \n",
      "theta: 10.0   pi: 6.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0002999151344173481\n",
      "Objective value:  2.893424326636496e-08\n",
      "Final_portfolio_weights  [ 1.86919668e-07 -4.16011956e-08 -8.47398389e-08]\n",
      " \n",
      "theta: 1000.0   pi: 0.5\n",
      "Converged with in 167 iterations\n",
      "Gradient norm: 1.7200371383132297e-06\n",
      "Objective value:  2.103095293272061e-08\n",
      "Final_portfolio_weights  [ 2.08763582e-09 -4.77664848e-10 -1.69649949e-09]\n",
      " \n",
      "theta: 1000.0   pi: 2.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.00020735296438177748\n",
      "Objective value:  2.210048196098591e-08\n",
      "Final_portfolio_weights  [ 1.25030319e-09  2.45261903e-10 -1.14045311e-09]\n",
      " \n",
      "theta: 1000.0   pi: 4.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.00010523835979286056\n",
      "Objective value:  2.4004379247625178e-08\n",
      "Final_portfolio_weights  [ 1.41455921e-09 -1.39980216e-10 -8.95273954e-10]\n",
      " \n",
      "theta: 1000.0   pi: 6.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0004261437218037935\n",
      "Objective value:  2.865558941422408e-08\n",
      "Final_portfolio_weights  [ 1.88251330e-09 -4.08728344e-10 -8.29792907e-10]\n",
      " \n",
      "theta: 100000.0   pi: 0.5\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0001287010725529898\n",
      "Objective value:  2.0152191795299737e-08\n",
      "Final_portfolio_weights  [ 2.12278490e-11 -4.40221777e-12 -1.65020199e-11]\n",
      " \n",
      "theta: 100000.0   pi: 2.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0002994147929438663\n",
      "Objective value:  2.1688097213718575e-08\n",
      "Final_portfolio_weights  [ 1.26690912e-11  2.60371085e-12 -1.11940300e-11]\n",
      " \n",
      "theta: 100000.0   pi: 4.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.00023642831340543334\n",
      "Objective value:  2.336700375567354e-08\n",
      "Final_portfolio_weights  [ 1.43216997e-11 -1.27818278e-12 -8.72637929e-12]\n",
      " \n",
      "theta: 100000.0   pi: 6.0\n",
      "Converged with in 238 iterations\n",
      "Gradient norm: 6.538181832007924e-05\n",
      "Objective value:  2.998084486469732e-08\n",
      "Final_portfolio_weights  [ 1.84704136e-11 -4.31396763e-12 -8.80519406e-12]\n",
      " \n",
      "theta: 1000000.0   pi: 0.5\n",
      "Max iteration reached\n",
      "Gradient norm: 0.00018330934240888848\n",
      "Objective value:  1.991540603233701e-08\n",
      "Final_portfolio_weights  [ 2.13789803e-12 -4.24859265e-13 -1.63018096e-12]\n",
      " \n",
      "theta: 1000000.0   pi: 2.0\n",
      "Converged with in 282 iterations\n",
      "Gradient norm: 4.388657504511211e-05\n",
      "Objective value:  2.2707952671370525e-08\n",
      "Final_portfolio_weights  [ 1.94656364e-12  8.78764817e-13 -2.57856256e-13]\n",
      " \n",
      "theta: 1000000.0   pi: 4.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.00028743567583801283\n",
      "Objective value:  2.3125744076136105e-08\n",
      "Final_portfolio_weights  [ 1.43901694e-12 -1.23089569e-13 -8.63836880e-13]\n",
      " \n",
      "theta: 1000000.0   pi: 6.0\n",
      "Max iteration reached\n",
      "Gradient norm: 0.0006501539618675743\n",
      "Objective value:  2.794209235844706e-08\n",
      "Final_portfolio_weights  [ 1.90731413e-12 -3.95835463e-13 -7.98954281e-13]\n"
     ]
    }
   ],
   "source": [
    "pis = np.array([0.5, 2, 4, 6])\n",
    "thetas = np.array([0.1, 10, 1000, 1e5, 1e6])\n",
    "weights_theta_pi = np.zeros([len(thetas),len(pis),3])   \n",
    "\n",
    "for i in range(len(thetas)):\n",
    "    for j in range(len(pis)):\n",
    "        n = 3  # Number of assets\n",
    "        T = 100  # Number of days\n",
    "        np.random.seed(10)\n",
    "        # Initial random portfolio weights.\n",
    "        theta = thetas[i]\n",
    "        pi = pis[j]\n",
    "        x_j = np.random.rand(n) \n",
    "        weights_theta_pi[i,j,:]=first_order(x_j, r_jt, bar_r_j, pi, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style='color:red'>Task 2: Benchmark your portfolio on the remaining days</span>\n",
    "#### On each of the remaining days, we proceed as follows.  Denote by $x^*$ your portfolio. At the market open we invest $10^9 x^*_j$ on each asset $j$, and we close the position (by) noon.  You need to use the asset's price to compute the number of shares that you invest in, whether long or short. So the total you invest equals $$ \\sum_{j = 1}^n 10^9 |x^*_j|.$$\n",
    "#### Report the average return earned by your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_return(x):   \n",
    "    # Extract percentage changes and drop NaN values\n",
    "    AMZN_test = np.array(df_AMZN[df_AMZN['Date'].isin(intersection_dates)].groupby('Date')['Close'].pct_change().dropna())[100:] \n",
    "    NFLX_test = np.array(df_NFLX[df_NFLX['Date'].isin(intersection_dates)].groupby('Date')['Close'].pct_change().dropna())[100:] \n",
    "    TSLA_test = np.array(df_TSLA[df_TSLA['Date'].isin(intersection_dates)].groupby('Date')['Close'].pct_change().dropna())[100:] \n",
    "    \n",
    "    # Stack the percentage changes\n",
    "    return_arr = np.column_stack((AMZN_test, NFLX_test, TSLA_test))\n",
    "    \n",
    "    total_return = 0\n",
    "    num_days = len(AMZN_test)\n",
    "    \n",
    "    # Normalize weights to sum to 1\n",
    "    x = x / np.sum(x)\n",
    "    \n",
    "    for i in range(num_days):\n",
    "        daily_return = 0\n",
    "\n",
    "        for j in range(3):\n",
    "            # Calculate the contribution of asset j to daily return\n",
    "            daily_return += np.sum(1e9 * x[j]) * return_arr[i][j]\n",
    "        \n",
    "        total_return += daily_return\n",
    "        \n",
    "    average_return = total_return / num_days\n",
    "    \n",
    "    return average_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: 0.1   pi: 0.5\n",
      "average return:  441545.7943917054\n",
      "theta: 0.1   pi: 2.0\n",
      "average return:  -4827651.62932147\n",
      "theta: 0.1   pi: 4.0\n",
      "average return:  129605.26522738372\n",
      "theta: 0.1   pi: 6.0\n",
      "average return:  236705.26300256213\n",
      "theta: 10.0   pi: 0.5\n",
      "average return:  211361.4633983196\n",
      "theta: 10.0   pi: 2.0\n",
      "average return:  -1201793.7304608535\n",
      "theta: 10.0   pi: 4.0\n",
      "average return:  565380.5371003367\n",
      "theta: 10.0   pi: 6.0\n",
      "average return:  100075.54761797763\n",
      "theta: 1000.0   pi: 0.5\n",
      "average return:  8212942.4540810725\n",
      "theta: 1000.0   pi: 2.0\n",
      "average return:  -798596.3079099151\n",
      "theta: 1000.0   pi: 4.0\n",
      "average return:  -333731.89641582104\n",
      "theta: 1000.0   pi: 6.0\n",
      "average return:  140668.569283059\n",
      "theta: 100000.0   pi: 0.5\n",
      "average return:  -19235420.53585599\n",
      "theta: 100000.0   pi: 2.0\n",
      "average return:  -598444.9383189494\n",
      "theta: 100000.0   pi: 4.0\n",
      "average return:  -199989.53185309068\n",
      "theta: 100000.0   pi: 6.0\n",
      "average return:  9660.447244069897\n",
      "theta: 1000000.0   pi: 0.5\n",
      "average return:  -7058170.710438893\n",
      "theta: 1000000.0   pi: 2.0\n",
      "average return:  534588.5133543144\n",
      "theta: 1000000.0   pi: 4.0\n",
      "average return:  -156361.69792807504\n",
      "theta: 1000000.0   pi: 6.0\n",
      "average return:  202166.54387755977\n"
     ]
    }
   ],
   "source": [
    "for i in range(weights_theta_pi.shape[0]):\n",
    "    for j in range(weights_theta_pi.shape[1]):\n",
    "            print('theta:', thetas[i],' ', 'pi:', pis[j])\n",
    "            print('average return: ', calculate_avg_return(weights_theta_pi[i, j]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
